# Model Comparison: Custom CNN vs Transfer Learning

## Overview

This document compares the **Before** (Custom CNN) and **After** (Transfer Learning with Pre-trained Models) implementations for QR Code Phishing Detection.

---

## üìä Quick Comparison Table

| Aspect | Before (Custom CNN) | After (Transfer Learning) |
|--------|---------------------|---------------------------|
| **Model Type** | Custom 3-layer CNN | Pre-trained ResNet/EfficientNet |
| **Parameters** | ~2.5M | ~11M (ResNet18) to ~25M (ResNet50) |
| **Training Time** | Longer (from scratch) | Shorter (fine-tuning) |
| **Expected Accuracy** | Baseline | **Higher** (typically 5-15% improvement) |
| **Data Requirements** | More data needed | Less data needed (pre-trained features) |
| **Implementation Complexity** | Simple | Simple (using timm library) |
| **Model Size** | ~10 MB | ~40-100 MB (depending on model) |
| **Inference Speed** | Fast | Slightly slower (larger model) |
| **Best For** | Learning, small datasets | Production, better accuracy |

---

## üîß Technical Changes

### 1. Model Architecture

#### Before: Custom CNN
```python
# Simple 3-layer CNN
Conv1 (3‚Üí32) ‚Üí Pool ‚Üí ReLU
Conv2 (32‚Üí64) ‚Üí Pool ‚Üí ReLU  
Conv3 (64‚Üí128) ‚Üí Pool ‚Üí ReLU
Flatten ‚Üí FC1 (512) ‚Üí FC2 (256) ‚Üí Output (2)
```

**Characteristics:**
- 3 convolutional layers
- 2 fully connected layers
- ~2.5M parameters
- Trained from scratch (random initialization)
- No pre-trained knowledge

#### After: Transfer Learning
```python
# Pre-trained ResNet18 (example)
Pre-trained Backbone (ImageNet features)
  ‚Üì
Replace final layer: 1000 classes ‚Üí 2 classes
  ‚Üì
Fine-tune on QR code data
```

**Characteristics:**
- Deep pre-trained architecture (18-50 layers)
- ~11M-25M parameters (depending on model)
- Pre-trained on ImageNet (1.2M images, 1000 classes)
- Fine-tuned on QR code data
- Leverages learned features (edges, shapes, textures)

---

### 2. Code Changes

#### Files Modified

1. **`pyproject.toml`**
   - **Before:** No timm dependency
   - **After:** Added `timm>=0.9.0` for pre-trained models

2. **`model.py`**
   - **Before:** Only `QRCodeCNN` class
   - **After:** 
     - Added `timm` import
     - Modified `create_model()` to support both CNN and transfer learning
     - Added `model_type` and `model_name` parameters

3. **`config.yaml`**
   - **Before:** No model type selection
   - **After:** 
     - Added `model_type: "transfer"` or `"cnn"`
     - Added `model_name: "resnet18"` (or other pre-trained models)

4. **`train.py` & `test.py`**
   - **Before:** Simple model creation
   - **After:** Pass `model_type` and `model_name` to `create_model()`

---

### 3. Configuration Changes

#### Before (config.yaml)
```yaml
model:
  num_classes: 2
  dropout: 0.3
  model_name: "qr_cnn_model"
  save_path: "best_model.pth"
```

#### After (config.yaml)
```yaml
model:
  model_type: "transfer"  # NEW: Choose "cnn" or "transfer"
  model_name: "resnet18"  # NEW: Pre-trained model name
  num_classes: 2
  dropout: 0.3
  save_path: "best_model.pth"
```

**Available Pre-trained Models:**
- `resnet18` - Fast, good balance (11M params)
- `resnet34` - Deeper, better accuracy (21M params)
- `resnet50` - Best accuracy, slower (25M params)
- `efficientnet_b0` - Efficient, mobile-friendly (5M params)
- `efficientnet_b1` - Better accuracy than B0 (8M params)
- `mobilenet_v3_small` - Very fast, small (2M params)
- `mobilenet_v3_large` - Better accuracy, still fast (5M params)

---

## üìà Expected Performance Improvements

### Accuracy Comparison

| Metric | Custom CNN | Transfer Learning (ResNet18) | Improvement |
|--------|-----------|----------------------------|-------------|
| **Training Accuracy** | ~75-80% | **~85-92%** | +10-12% |
| **Validation Accuracy** | ~73-78% | **~83-90%** | +10-12% |
| **Test Accuracy** | ~72-77% | **~82-89%** | +10-12% |
| **F1-Score** | ~0.72-0.77 | **~0.82-0.89** | +0.10-0.12 |

*Note: Actual results depend on dataset, hyperparameters, and training duration*

### Training Efficiency

| Aspect | Custom CNN | Transfer Learning |
|--------|-----------|-------------------|
| **Epochs to Converge** | 10-15 epochs | **5-8 epochs** |
| **Time per Epoch** | Baseline | Similar or faster |
| **Total Training Time** | Longer | **Shorter** (fewer epochs needed) |
| **Data Needed** | More | **Less** (pre-trained features help) |

---

## üéØ Key Advantages of Transfer Learning

### 1. **Better Feature Extraction**
- Pre-trained models learned rich features from ImageNet
- Can detect edges, textures, patterns, and complex structures
- These features transfer well to QR code classification

### 2. **Faster Convergence**
- Model starts with good weights (not random)
- Requires fewer epochs to reach good performance
- Saves training time and computational resources

### 3. **Better Generalization**
- Pre-trained models are more robust
- Less prone to overfitting
- Better performance on unseen data

### 4. **Less Data Required**
- Can achieve good results with smaller datasets
- Pre-trained features reduce data requirements
- Important when you have limited labeled data

### 5. **Proven Architecture**
- ResNet, EfficientNet are battle-tested architectures
- Used in production systems worldwide
- Well-optimized and efficient

---

## ‚ö†Ô∏è Trade-offs and Considerations

### Disadvantages of Transfer Learning

1. **Larger Model Size**
   - ResNet18: ~40 MB vs Custom CNN: ~10 MB
   - More memory required during inference

2. **Slightly Slower Inference**
   - More parameters = slightly slower forward pass
   - Still very fast (milliseconds per image)

3. **Requires Internet (First Time)**
   - Downloads pre-trained weights (~40-100 MB)
   - Only needed once, then cached locally

4. **More Parameters**
   - More memory during training
   - May need to reduce batch size on limited GPU memory

---

## üîÑ How to Switch Between Models

### Using Custom CNN (Before)
```yaml
# config.yaml
model:
  model_type: "cnn"  # Use custom CNN
  num_classes: 2
  dropout: 0.3
```

### Using Transfer Learning (After)
```yaml
# config.yaml
model:
  model_type: "transfer"  # Use pre-trained model
  model_name: "resnet18"   # Choose model
  num_classes: 2
  dropout: 0.3
```

**No code changes needed!** Just modify `config.yaml` and run training.

---

## üìù Code Comparison

### Model Creation - Before
```python
# model.py - Before
def create_model(num_classes=2, dropout=0.5, device='cpu'):
    model = QRCodeCNN(num_classes=num_classes, dropout=dropout)
    # Initialize weights from scratch
    model.apply(init_weights)
    return model.to(device)
```

### Model Creation - After
```python
# model.py - After
def create_model(num_classes=2, dropout=0.5, device='cpu', 
                 model_type='cnn', model_name='resnet18'):
    if model_type == 'transfer':
        # Load pre-trained model
        model = timm.create_model(
            model_name,
            pretrained=True,
            num_classes=num_classes,
            drop_rate=dropout
        )
    else:
        # Use custom CNN (backward compatible)
        model = QRCodeCNN(num_classes=num_classes, dropout=dropout)
        model.apply(init_weights)
    
    return model.to(device)
```

**Key Difference:** After version supports both CNN and transfer learning, making it backward compatible.

---

## üöÄ Usage Examples

### Example 1: Quick Start with ResNet18
```yaml
# config.yaml
model:
  model_type: "transfer"
  model_name: "resnet18"  # Fast and accurate
```

### Example 2: Best Accuracy with ResNet50
```yaml
# config.yaml
model:
  model_type: "transfer"
  model_name: "resnet50"  # Best accuracy, slower
```

### Example 3: Fast Inference with MobileNet
```yaml
# config.yaml
model:
  model_type: "transfer"
  model_name: "mobilenet_v3_small"  # Very fast, smaller model
```

### Example 4: Back to Custom CNN
```yaml
# config.yaml
model:
  model_type: "cnn"  # Use original custom CNN
```

---

## üìä Model Size Comparison

| Model | Parameters | Model Size (MB) | Inference Speed |
|-------|-----------|-----------------|-----------------|
| **Custom CNN** | 2.5M | ~10 MB | Fastest |
| **ResNet18** | 11.7M | ~45 MB | Fast |
| **ResNet34** | 21.8M | ~85 MB | Medium |
| **ResNet50** | 25.6M | ~100 MB | Slower |
| **EfficientNet-B0** | 5.3M | ~20 MB | Fast |
| **MobileNet-V3-Small** | 2.5M | ~10 MB | Very Fast |

---

## üéì Learning Points

### What Transfer Learning Teaches Us:

1. **Reusability**: Pre-trained models can be adapted to new tasks
2. **Efficiency**: Don't reinvent the wheel - leverage existing knowledge
3. **Performance**: Pre-trained models often outperform custom architectures
4. **Flexibility**: Easy to switch between models via configuration

### When to Use Each:

**Use Custom CNN when:**
- Learning/educational purposes
- Very specific architecture requirements
- Extremely limited computational resources
- Want full control over architecture

**Use Transfer Learning when:**
- Want best accuracy
- Limited training data
- Production deployment
- Need faster development

---

## ‚úÖ Summary

### What Changed:
- ‚úÖ Added support for pre-trained models (ResNet, EfficientNet, MobileNet)
- ‚úÖ Backward compatible (can still use custom CNN)
- ‚úÖ Easy configuration via `config.yaml`
- ‚úÖ No breaking changes to existing code

### What Stayed the Same:
- ‚úÖ Training pipeline (`train.py`)
- ‚úÖ Evaluation pipeline (`test.py`)
- ‚úÖ Data loading (`dataset.py`, `data_utils.py`)
- ‚úÖ Configuration structure
- ‚úÖ All existing features (wandb, early stopping, etc.)

### Expected Results:
- ‚úÖ **10-15% accuracy improvement**
- ‚úÖ **Faster convergence** (fewer epochs)
- ‚úÖ **Better generalization**
- ‚úÖ **Production-ready** architecture

---

## üîÆ Next Steps

1. **Train with Transfer Learning**: Set `model_type: "transfer"` in config
2. **Compare Results**: Run both CNN and transfer learning, compare metrics
3. **Experiment**: Try different pre-trained models (ResNet18, EfficientNet, etc.)
4. **Fine-tune**: Adjust learning rate, dropout for optimal performance
5. **Deploy**: Use the best performing model for production

---

**Last Updated:** After implementing Transfer Learning support
**Status:** ‚úÖ Ready to use - Just change `model_type` in `config.yaml`!

