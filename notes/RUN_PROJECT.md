# Complete Project Run Flow

## ðŸŽ¯ Step-by-Step Guide to Run the Project

### Prerequisites Check
```bash
# 1. Navigate to project directory
cd /home/zuss/pytorch/quishing-with-ml

# 2. Verify dependencies are installed
uv sync

# 3. Check if wandb is available (optional)
python -c "import wandb; print('Wandb available')" || echo "Wandb not installed"
```

---

## ðŸ“‹ Phase 1: Quick Tests (5-10 minutes)

**Purpose**: Verify all components work before full training

### Test 1: Dataset Loading
```bash
uv run test_dataset.py
```
**Expected Output**: 
- âœ… Dataset initialized with images
- âœ… Image shape: torch.Size([3, 224, 224])
- âœ… Labels working correctly

### Test 2: Data Splitting
```bash
uv run test_data_splits.py
```
**Expected Output**:
- âœ… Train/Val/Test splits created
- âœ… DataLoaders working
- âœ… Batch loading successful

### Test 3: Model Architecture
```bash
uv run test_model.py
```
**Expected Output**:
- âœ… Model created successfully
- âœ… Forward pass works
- âœ… Optimizer (AdamW) initialized
- âœ… Scheduler working

### Test 4: Training Setup (Quick)
```bash
uv run test_train_quick.py
```
**Expected Output**:
- âœ… Training step works
- âœ… Validation step works
- âœ… Loss computed correctly

**If all tests pass â†’ Proceed to Phase 2**

---

## ðŸš€ Phase 2: Full Training (2-4 hours on CPU)

### Step 1: Setup Wandb (Optional but Recommended)

```bash
# Login to wandb (first time only)
wandb login
# Enter your API key from https://wandb.ai/authorize
```

### Step 2: Configure Wandb in config.yaml

Edit `config.yaml`:
```yaml
logging:
  use_wandb: true  # Change from false to true
  wandb_project: "qr-phishing-detection"
  wandb_entity: null  # Or your username
```

### Step 3: Review Training Configuration

Check `config.yaml` settings:
```yaml
data:
  sample_size: 5000  # Images per class (10K total)
  
training:
  batch_size: 32
  epochs: 10
  learning_rate: 0.001
```

### Step 4: Start Training

```bash
uv run train.py
```

### What Happens During Training:

1. **Data Loading** (1-2 minutes)
   - Samples 5,000 images per class
   - Creates train/val/test splits
   - Creates DataLoaders

2. **Model Creation** (< 1 minute)
   - Creates CNN model
   - Initializes optimizer (AdamW)
   - Sets up scheduler

3. **Wandb Initialization** (if enabled)
   - Logs: "âœ“ Weights & Biases initialized"
   - Starts tracking run

4. **Training Loop** (10 epochs Ã— ~10-15 min = 2-2.5 hours)
   ```
   For each epoch:uv 
   â”œâ”€â”€ Training Phase (~10-15 min)
   â”‚   â”œâ”€â”€ Forward pass
   â”‚   â”œâ”€â”€ Loss computation
   â”‚   â”œâ”€â”€ Backward pass
   â”‚   â””â”€â”€ Weight update
   â”‚
   â”œâ”€â”€ Validation Phase (~2-3 min)
   â”‚   â”œâ”€â”€ Forward pass (no gradients)
   â”‚   â””â”€â”€ Metrics computation
   â”‚
   â”œâ”€â”€ Logging to Wandb (if enabled)
   â”‚   â”œâ”€â”€ Train/Val Loss
   â”‚   â”œâ”€â”€ Train/Val Accuracy
   â”‚   â”œâ”€â”€ Learning Rate
   â”‚   â””â”€â”€ Best metrics
   â”‚
   â””â”€â”€ Model Saving
       â””â”€â”€ Saves if validation loss improved
   ```

5. **Training Complete**
   - Best model saved to `models/best_model.pth`
   - Training plots saved to `models/training_history.png`
   - Wandb run completed

### Expected Console Output:
```
Using device: cpu
============================================================
Loading data...
Creating Data Splits (Option A: Sampling Strategy)
Sampling 5000 images per class...
...

Creating model...
Model parameters: 51,539,906
Model size: 196.61 MB

âœ“ Weights & Biases initialized  # If wandb enabled

============================================================
Starting Training
============================================================
Epoch 1/10
------------------------------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 219/219 [10:23<00:00, 1.65s/it]
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [02:15<00:00, 2.88s/it]
Train Loss: 0.6234 | Train Acc: 65.23%
Val Loss:   0.5891 | Val Acc:   68.45%
LR: 0.001000
âœ“ Saved best model (Val Loss: 0.5891)

Epoch 2/10
...

============================================================
Training Complete!
============================================================
Total training time: 125.34 minutes
Best validation loss: 0.2345
Best validation accuracy: 89.23%
Model saved to: models/best_model.pth
Training plots saved to: models/training_history.png
âœ“ Wandb run completed
```

### Verify Wandb Logging:

1. **During Training**: Check console for:
   - "âœ“ Weights & Biases initialized"
   - No errors about wandb

2. **After Training**: Check console for:
   - "âœ“ Wandb run completed"

3. **Online Dashboard**: 
   - Go to https://wandb.ai
   - Navigate to project: `qr-phishing-detection`
   - See your run with all metrics!

---

## ðŸ“Š Phase 3: Evaluation (5-10 minutes)

### Step 1: Run Evaluation

```bash
uv run test.py
```

### What Happens:

1. **Load Model** (< 1 minute)
   - Loads `models/best_model.pth`
   - Displays model info

2. **Load Test Data** (< 1 minute)
   - Uses same data splits as training

3. **Evaluate** (2-5 minutes)
   - Forward pass on test set
   - Computes all metrics

4. **Generate Reports** (< 1 minute)
   - Confusion matrix plot
   - Classification report

### Expected Output:
```
Using device: cpu
============================================================
Loading test data...
Loading model...
Model loaded from: models/best_model.pth
Model was trained for 10 epochs
Best validation accuracy: 89.23%

============================================================
Evaluating on Test Set
============================================================
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [XX:XX<00:00, X.XXit/s]

============================================================
EVALUATION METRICS
============================================================
Overall Metrics:
  Accuracy:  0.8923 (89.23%)
  Precision: 0.8934 (89.34%)
  Recall:    0.8923 (89.23%)
  F1-Score:  0.8928 (89.28%)

...

Confusion matrix saved to: models/confusion_matrix.png
```

---

## ðŸ” Verification Checklist

### âœ… After Phase 1 (Tests):
- [ ] All 4 test scripts pass
- [ ] No errors in console

### âœ… After Phase 2 (Training):
- [ ] Training completes without errors
- [ ] Model saved: `models/best_model.pth` exists
- [ ] Plot saved: `models/training_history.png` exists
- [ ] Wandb: Run visible at wandb.ai (if enabled)
- [ ] Wandb: Metrics logged (loss, accuracy, LR)
- [ ] Console shows: "âœ“ Wandb run completed"

### âœ… After Phase 3 (Evaluation):
- [ ] Evaluation completes successfully
- [ ] All metrics printed
- [ ] Confusion matrix saved: `models/confusion_matrix.png`
- [ ] Test accuracy reported

---

## ðŸ› Troubleshooting

### Wandb Not Logging?

1. **Check if enabled**:
   ```bash
   grep "use_wandb" config.yaml
   # Should show: use_wandb: true
   ```

2. **Check if logged in**:
   ```bash
   wandb login
   # Should say: Successfully logged in
   ```

3. **Check console output**:
   - Should see: "âœ“ Weights & Biases initialized"
   - Should see: "âœ“ Wandb run completed"

4. **Check wandb.ai**:
   - Go to https://wandb.ai
   - Check project: `qr-phishing-detection`
   - Should see your run

### Training Too Slow?

- Reduce `sample_size` in config.yaml (e.g., 2000 instead of 5000)
- Reduce `batch_size` if memory issues
- Reduce `epochs` for quick test

### Out of Memory?

- Reduce `batch_size` in config.yaml (e.g., 16 instead of 32)
- Reduce `sample_size` (fewer images)
- Reduce `image_size` (e.g., 128 instead of 224)

---

## ðŸ“ˆ Complete Flow Summary

```
1. Quick Tests (5-10 min)
   â”œâ”€â”€ test_dataset.py âœ…
   â”œâ”€â”€ test_data_splits.py âœ…
   â”œâ”€â”€ test_model.py âœ…
   â””â”€â”€ test_train_quick.py âœ…

2. Full Training (2-4 hours)
   â”œâ”€â”€ Setup wandb (login + config)
   â”œâ”€â”€ Run: uv run train.py
   â”œâ”€â”€ Monitor console output
   â”œâ”€â”€ Check wandb.ai dashboard
   â””â”€â”€ Verify model saved

3. Evaluation (5-10 min)
   â”œâ”€â”€ Run: uv run test.py
   â”œâ”€â”€ Review metrics
   â””â”€â”€ Check plots generated
```

---

## ðŸŽ¯ Quick Start (Minimal)

If you just want to verify everything works quickly:

```bash
# 1. Quick tests
uv run test_dataset.py
uv run test_data_splits.py
uv run test_model.py
uv run test_train_quick.py

# 2. Quick training (small sample, few epochs)
# Edit config.yaml: sample_size: 100, epochs: 2
uv run train.py

# 3. Evaluate
uv run test.py
```

This will take ~15-20 minutes instead of 2-4 hours!

